Speaker 1: Awesome. So welcome everyone to Medigov seminar. My name is Val, and I'm the community lead at Medigov. Medigov is a laboratory for digital governance. And every week, we invite researchers from the governance space broadly to share their work with us. And so today, I'm super, super excited to introduce our speakers. We have Richard Witt and Stephanie Gouveia who are the leaders of a group called the Alliance. And, the Alliance is a I mean, I'll let them do the introduction, and explanation. But, basically, I'm super excited about what they're working on because, I think a lot of the companies out there that are handling our data on the Internet these days need, to be kind of checked. And this, framework that they have built and provided, kind of injects that into the legal policies of these companies in a really innovative way. So I I was really inspired to come across Richard, meet him, learn about his work, and, and then hear how him and Stephanie are really putting this into practice with startups that they advise. So, I'm super inspired and excited to hear all about what they're working on and and how they've done it. So welcome, and I'll pass the floor to you. And feel free to send questions. Sorry. Feel free to send questions in the chat as they're presenting, and we'll get to them. Yeah.

Speaker 2: Yeah. Absolutely. Thanks so much, Val. And I'm glad I got, I think, four or five supers out of you in that two minute intro. So that that to get to get that from Val is is is super wonderful. So, appreciate the invitation, appreciate the chance to to chat with you all. And, I think, Stephanie, I think you need to put the slide deck fully up. I think it's just It's not it's

Speaker 3: You don't see it yet?

Speaker 2: Slideshow that you put in I mean, we we we see the deck.

Speaker 3: I do. Okay. I don't even do that. Okay. Of course.

Speaker 2: Up on top. Up right. Yeah. Oh, yeah. Yeah. Yeah. That's it. Yep.

Speaker 3: Thank you.

Speaker 2: Thank you. Yeah. I'm gonna have Stephanie run the slide deck because, ironically, as a tech lawyer for thirty five years, I'm not great with tech. So, anyway, we are here with the Clionet Alliance. We're happy to to talk to you today. This is really we'll we'll show slides, but I'd love this to be more about a conversation. I'm really impressed by what MediGov has put together, the things you all do. We could certainly use your assistance as we are building out our little community of of trust around what we call net fiduciaries. And so if if there's some room for fruitful collaboration in the near future, that would be great. So I'll just give you a little bit of background here about who we are, what we're doing, and then, yeah, happy to have you drop stuff in chat, interrupt me, and or Stephanie as we're chatting. And, yeah, we'll just get going from here. So thanks, Stephanie. So who the heck am I? I'm, I've been around the tech industry for about thirty five years. I started out, representing some of the early pre web companies in in a law firm in Washington DC in the late eighties. So CompuServe and Prodigy and AOL, for those of you who who enjoy ancient history of the web. I then went on to twelve years at MCI Communications where I founded a Internet data policy group, one of the first ones in Washington in the nineties. Met Vint Cerf, father co father of the Internet, who's become a friend and mentor to me since then. Moved on to Google for twelve years, the first seven in the DC office, the last four and a half out in Mountain View, the headquarters. Moved on in 2018, joined Mozilla as a fellow, and these ideas around and the Glionet, foundations sort of started there. And, so it's been a a great a great journey since then and leading me to writing a book that came out last fall called Reweaving the Web. And I now currently live in Washington, DC. So there's the book. It's a deep dive into the trust deficit, as I say. One of my reasons for writing it is, you know, you we see an awful lot out there these days about the problems with with the web, the challenges of when there are people not having control over their data, over the algorithms that are making decisions on their behalf, all the tech that's not serving us. And yet I haven't really seen a whole lot of proposed solutions, at least ones that I thought made sense and could provide real meaningful change. So the book does do a bit in the front about what the problems are, but it's mostly focused what I think are the solutions, at least a set of solutions. And I'm the very first to say there's many routes to take. Mine is, yep, is just one one suggestion. There are many others. But, I this was one I'm committed to because I felt like it's got a a shot of actually doing some real good in the world. And, it's this digital ecosystem that I call Glionet. So next slide, Stephanie. So next slide, Stephanie. So, what is this thing called Glionet? So, as I said, the the first forty, fifty pages of the book is talks about what I call the seams cycles. A lot of this comes from Shoshana Zuboff. She wrote her amazing book on surveillance capitalism. Right? And this is really just an attempt to sort of pull together other peoples into a sort of a single sort of set of feedback loops that people, can understand and appreciate and and hopefully resist. So I call it SEAMS, which stands for surveillance, extraction, analysis, and manipulation. And I think all four of those, we're all pretty well acquainted with at this juncture. The manipulation part, when I first came up with that phrase going back eight, nine years, seemed a little tough. Some people pushed back and said, well, no. No. They're not really doing things influenced by behaviors. But, of course, as Shoshana and many others have amplified them documented that is actually the case a 100%. And the analysis part there now with AI, not just the AI platforms, now the coming of agents. They wanna do more. They wanna understand us at a deeper level, the platform companies, in ways to influence and manipulate our our behaviors, the way we think about the world, the way we see the world. It's already happening, and there's more of that coming on the way. So what we need is a new ecosystem of trust, what I call glia net. So glia is the ancient Greek word for glue. Came about, and I use it for three connotations. One is the saying that trust is the social glue that binds us together. Obviously, within not just The United States, but globally, trust in institutions has been on the decline in years, whether it's the media, whether it's governments, you know, other sort of institutions of authority. The web didn't create that problem, but it certainly, I would say, has helped exacerbate it. And so we need to find ways of building authentic trust again between people. Accountability, as in Spider Man's mantra, with great power comes great responsibility. The tech folks tend not to answer for it. Most people focus on this accountability piece. Like, just as I say, make the platforms hurt me a little bit less than they did yesterday. It's absolutely important and critical work, but it's not sufficient. I think we need to move past accountability to an agenda of what I call agency, which I'll talk about in a second, where it's more about empowering those of us who use the technology, not just about reining in to some degree the platform companies who are supplying it to us. And then the support part is also important. Late in the nineteenth century, when they first started to look at the human brain, using the sort of the technology at the time, they looked at, this, all the electrical signals that were flashing around, and that was the neural network, which is very exciting they hadn't seen before. And yet there was stuff in between that looked inert matter that wasn't doing anything. And they said, oh, well, it doesn't really seem to be doing much except glue the neurons together. Let's let's call them the glials. So that's where they actually took that term from the Greek language. Well, it turns out the glial cells act on chemicals, not on electricals impulses. So there was they were not showing up in those scans. Ironically, they've now discovered in recent years the glial cells do an amazing amount of things to support the the the healthiness of the neural systems. And so the neural function couldn't survive without that support network of the glial cells. So I like that as sort of an analogy as well that all of us need that kind of support online. None of us should be standing alone, bravely against the onslaught of what the tech companies and others are doing. We need a support system to help us. I also like to joke that here in Silicon Valley, when you go to a typical happy hour, you're surrounded by by neural networks, not a whole lot of glial networks in the mix. So, I think we need to change that as well. Anyway, move on, Stephanie to the next slide. So, the thinking here is we need to create an ecosystem or system space or modular layers space, however you want to look at it, the multi the multiple modalities around what makes a particular system work. And there are four of them as I see it, primarily where you can create change that has an effect on all the others. And that if you create change at all four of these different layers, then you're creating real sustainable, meaningful change going forward. Governance is the first one. And we'll talk more about this in a second. But it's it's basically creating a new class of intermediaries to benefit us. We call them net fiduciaries. And it's at the the governance layer is often, again, the part that's left behind when we talk about technology. Most you know, you talk about things like blockchain or digital identity IDs or, you know, personal data pods in my living room or what have you. There's lots of itch interesting technologies out there that can empower the ordinary person, but there's no, like, governance typically that goes along with the technology to ensure that that tech is actually being used in ethical ways that actually meet meet the the requirements of the end user. So that's where the governance layer, I think, is important and and the overarching element here and, of course, what you at MediGov work on all the time, which is which is great. The second piece is markets. So we need a new kind of marketplace of willing sellers and buyers. I like to say the web has essentially bastardized the notion of what a market actually looks like because the way that they use the seams, paradigm, as I mentioned earlier, in other modes, it's not really a market. They're, more or less imposing themselves on us. And because we get free cat videos out of that, we're okay with it for the most part. But I think we we should expect a lot more, particularly in the age of AI. Technology is the third piece, and that's the advanced tech, the applications and devices. We're now at the the very dawn of the personal agent, the AI agent, that every platform wants to have sitting in your hip pocket, basically listening in and providing input to you, and output to them at every moment, which I think is, wonderful as a potential way of of of bolstering us as human beings and frightening given who the people are who are in charge of that technology. And then final piece is public policy. So are there elements we can do in terms of interacting with policymakers, whether in national state level here in The US or or globally in other places. So these are the four elements of what we call the trust fabric and the need to sort of create change at each of those different layers. Next one, Stephanie. So what is a net fiduciary? So as a lawyer, I took this from my understanding of the common law, when I was in law school. The idea is going back hundreds of years in this case from from England. But interestingly, the concepts are much broader and deeper than just simply the common law of England. It's really found in many many, religions, cultures, societies around the world. And the notion is fairly straightforward. When you have an individual and then you have some sort of other entity, institution, even other individual who has the there's created what what has been called a power imbalance or power asymmetry based on several factors. One of them is an the classic case here is a doctor. Right? A doctor has training. She can help me figure out what's wrong with me, based on that training. So that's expertise that she has that I lack, which creates a power asymmetry between us. And then in addition to that, in order for her to help me, I need to be able to tell her what's going on. It could be something really embarrassing that I wouldn't want the rest of the world to know about, but I'm willing to convey it to her because by doing so, she can understand it, she can diagnose, and she can make me better. So doctors are the classic cases of the fiduciary elements, the common law duties of care, good faith, and loyalty. So when I'm in the city of the doctor's office, this is the ideal, of course. I am her patient. As her patient, she owes me a duty of care, not to harm me, but also a duty of loyalty to make me better. Right? So these are things that over a period of time, society has determined we want our physicians to operate under because of these power imbalances, and to create trust so that people want to go to see their doctor because they have a pretty good sense that your doctor know the day is gonna help you, make you better. And so that is the notion of sort of the time elements of of of care, confidentiality, good faith, and loyalty, which, again, is not just in the common law, but you they find it. The experts in the in the in the history of fiduciaries has has seen that many other places around the world. So it's not a universal, but it's a near universal notion. And so the idea here then is to take that concept, bring it now to the twenty first century, bring it to the web. Now I would say with all the data that people have around us, my personal data, now the algorithms that they're making decisions ostensibly on my behalf, we are now in a very similar, if not a bigger power asymmetry than we've dealt with in the past. And, therefore, we need sort of a new set of a new class of individuals, of entities to help us, and we call that the net fiduciary. So I see Val has a question in here, and the net fiduciary is its own legal entity that could be corporate co op. It could be applied to any legal entity. It's a great question. The short answer is it could be applied to any kind of entity. So, what we're doing in the alliance, I'll talk about it in a moment, we're mostly working with smaller startups who want to do this in a in a in a for profit context. It can also, though, happen and and as a net fiduciary specifically is sort of this entity to an individual or a set of individuals. There are other forms of fiduciary relationships, data co ops, data commons, you know, I think of the calls for the data collectives. It's a different model, but it's very much the same. There's a trust created, and there are fiduciary duties that are owed. And so what I like about one of the things I like about this concept, then you can import this into other places. So a b corp is a place where people have aligned to a certain ethical standard, but it's a fairly broad standard around how you treat people, you know, where the obligations are in in terms of what that particular company is signing up to. There's a trust mark that goes with that. The net fiduciary basically just sort of be put on top of that and say, okay. Yes. B Corp and this as well because it's more specific to data and to algorithms. It's more it's more it's more targeted focused on the web, whereas the B corp is a sort of a broader concept about operating under sort of general principles. It could be so a B corp or other cooperative or an ordinary for profit company, a nonprofit company, even a government agency, any of them could potentially sign up to to have these fiduciary duties. So, hopefully, the as I say, because the elements of being a fiduciary are are well understood, and and I think they're flexible enough to apply to lots of different contexts. Different contexts. Next slide, Stephanie. So this is a quick guide that we've put together on the three kind of the three types of elements of the fiduciary duties, And we call them promote, enhance, and protect, and they line up more or less with the common law duties of loyalty, fidelity, and care. So the lowest level is protect, and we call that the guardian. And that's a good example about that. The do no harm standard is make sure my data is well protected. So safeguarding my data, you know, someplace, making sure all the the elements of it are are securely locked away from prying eyes, help maybe protect my identity from people who wanna try to steal my identity, various elements around sort of a protection. You can almost think about this like putting a moat around the individual. That that sort of role is consistent with the the the do no harm, care standard, of that we call protect. And then there are two kinds of what have been normally called loyalty. And I break them out because I think it's important. The middle one I call fidelity. The top one is loyalty. And the, the middle one, the enhanced function, is this notion of not having conflicts of interest. And if there are conflicts of interest, between, say, serving an individual, if you're a doctor, and as your patient, and then also serving the healthcare system, and then also dealing with pharmaceutical companies, right, those are potential conflicts of interest. Right? Absolutely. We all are pretty well familiar with that. The idea here is that those are very transparent, well known, and that they're always dealt with in a way that, at the end of the day, the fidelity to the client, in this case, the patient as a doctor, comes out ahead. So they are the primary focus, of the of the relationship. An example from the web is helping me mediate my newsfeeds. So acting as sort of a a mediator, to ensure that I'm getting certain things that I want without getting things I don't want. Then the highest level of loyalty is often called the best interest standard, which is to promote my best interest affirmatively, be my advocate, be my entity in the world to to to promote interest. So way to think about this, if you're protecting, it's sort of a step back. Enhancing is sort of this moderating between conflicting elements. Promoting is really getting out there in the world, really being my my advocate. And the best case of this, I think, is is comes from Doc Searls, we call this IntentCast Shopping. So my universal shopping cart that goes out, synonymously into shopping at different websites on my behalf, not somebody else's behalf. Right? And so, it's done in a way that I am in charge of that relationship. I share as much or as little of my data as I want to. I create a connection if I want to or not with any of the places that the shopping cart goes to, But I'm casting my intentions, maybe my terms of service in my browser to the websites so that only the places go, that I that I tend to are the ones that I I I want to because they meet my my sense of of terms and not somebody else's. So that's the the sort of the three layers of what we consider the PEP model. And so then how do you apply this, in the in the real world? Well, this is an example pretty recently now because of we're now in the the age of of authentic AI of of personal AI agents. And so here, we have the client who is being served by a net fiduciary along with a personal AI. So you have that what I call the edge tech of the AI technology aligned with the net net fiduciary. So you have the governance of a fiduciary plus the technology, and then that becomes the way that you interact with the Googles, Amazons, Metas, OpenAI's, and others of the world. Of course, they want you to adopt their agents to become yours, but that's not really the right way to go. And we'll talk about a little bit more about that in a second. That's the that's the way they would like to set it up because that's the web paradigm. And what we're suggesting here is a very different paradigm starting with the individual, empowering her, and then giving her the tools necessary under the appropriate governance structure to to engage with the web. Okay. Next one, Stephanie. I won't go into this. We have a lot of detail on some of these slides. We're happy to share these afterwards as well. But this is just, a theory of change along these elements of governance, technology, and the social fabric. And the basic concept is, we would we believe that the notion of a net fiduciary is not just ethically sound. It's also meaningfully commercially successful. That if you create authentic trust relationships with what has been an end user but is now a customer or a client or a patron, you are you are doing something that actually creates authentic trust. If you can serve their interests over time, build that as a relationship, that individual will share more of themselves with the entity because it's it makes sense to because there's ways the entity can them, right, in terms of their interactions with the web. So it creates a market structure that's much more balanced between where we've been for in the past with the web. And then along with that, the technology of the personal AI agent. It's not Sam Altman's agent. It should be your agent interacting with Sam Altman's agent. And there are companies building that out. Some of them are members of our of our alliance. And so this combination, again, of the governance of the fiduciary, the technology of the personal AI together has a has a particular proposed impact down the road that we think is is reasonable. We think this is attainable. And by laying it out this way, hopefully, people can kick the tires and see if they agree and, obviously, show us where they think their thing so we keep doing, that are different, which is why it's called a provisional theory of change and always will be because we're never really gonna have the absolute every everything nailed down. Things will change. The environment changes, technology, etcetera etcetera is always evolving. But this is where because this hopefully gives people a sense of where we're we're heading. So what is this alliance, Glionet? So we started this up, roughly in concert with the release of my book last fall. It is a co what I call Coalition of the Willing. So it's the world's first assemblage of for profit companies who want to become a net fiduciary. So it's to create the governance structures around that, the technologies, you know, some of the the business models and market structures necessary to to implement it, and then advocating on behalf of, the collective, community of these companies in the public policy realm to the extent that is useful for us to to gain certain things from from policymakers. So it's attacking each of those four layers that I mentioned earlier, the sort of the the trust stack, in ways that the companies can then benefit from and then open source that to the rest of the world. So the notion is this is all as we're developing these different elements, this all becomes something that others can can learn from hopefully at the same time. Okay. Next one, Stephanie. Our statement of principles is pretty straightforward. We acknowledge that, basically, today's web sucks, and that we embrace the idea of of ethical business practices. We want to explore and apply governance around net fiduciaries. We wanna collaborate with others, whether it's those in within our community, but also like minded stakeholders, perhaps folks at Medigov, and is such a coalition of the willing to develop code of conduct and best practices and standards around all of this, and then endorse their voluntary involvement in the Alliance Act activities. So that is what every member agrees to when they sign up to join the Glionet Alliance. We have 20 members so far. Also, it's I wanna make clear membership is free. There's no obligation for anybody to join. And, because, frankly, from my side, it it benefits me enormously if there are companies willing to adopt this approach, and still also making money in the marketplace to help validate what we're trying to accomplish here. So, Stephanie, so this is the little road map. We've sort of come through phase one and two, which is our formation and the initial frameworks we're now in phase three there in the middle, which is building a community of practice. This is where I think, chatting with folks within MediGov would be of particular help and assistance to us and hopefully mutual benefit to you all as well. So we have a number of working groups assigned to these different elements of building a community of practice. What's a business model that matches up to what we think an Fiduciary should be and what is not? We should make that very clear. What kind of policy should be adopted? You know, a privacy policy that the first sentence says it's your data, not ours, is very different than the normal privacy policy we see written by lawyers, at places like Google. So what do those look like, and how can they be adopted? What practices do you implement internally to ensure that your your your policies are are in place? What kind of technical standards can you create? Sorry, Stephanie. Are you losing the slideshow?

Speaker 3: I just unmuted myself. Sorry.

Speaker 2: Okay. No worries. Continue.

Speaker 3: Yeah.

Speaker 2: Yeah. Yeah. Fine. Technical standards to implement all this, like, AI to AI interoperability, public policy agenda, as I mentioned, are there things we need from policymakers, and then an engagement and outreach, such as we're doing here today with with others who might be interested in in working with us. And then phase four is a community of practitioners. So moving from developing sort of the intellectual infrastructure into actual implementation in the world with a code of conduct, with certification, licensing, trust marks, with compliance and enforcement. A huge part of this is gonna have to be ensuring that anybody who becomes a net fiduciary is subject to enforcement and that those who interact with them have recourse if things go badly, and then also a potential government role. So this is where we are in the next, I would say, year to two years as we're continuing to build out the the the alliance is phase three looking ahead towards phase four to these different elements. Next one.

Speaker 3: Yes. Hey, everyone. I'm Stephanie. I'm the director of community engagement and outreach here at the Glionet Alliance, helping Richard out. As the director of community engagement, I'd like to just to give you an overall view of how we're doing this in our community of practice. So you'll notice the first, co design stage. This is really where we're, making sure that our working groups are actually helping them develop our priorities for this first half of the year. Such working groups can also then become interest groups or steering groups in in the works of, you know, how we end up developing some of the templates that we're working on. We hope to have different types of formats for knowledge exchange. We've already began doing this with some of our founding members. They're joining us, and they're talking about their own, startups in our founding member meetings. And then, of course, this is also the time when we're also exploring what it means to have our own internal community of practice as well as the rest of the world, so externally. We try to also do, focused workshops with academics and other stakeholders to produce these deliverables. We hope to do more of that this year. And, of course, I've mentioned a little bit about the showcase and opportunities of our founding members. Eventually, we hope that this does become a living body of knowledge, and we create this movement by really developing these comprehensive toolkits, creating this repository of the shared solution by our own practitioners, empowering another community of shared learners overall. Just some current stats. We have eight total working groups. Of these eight, five of them are up and running. You'll notice that, as Richard mentioned, we do have 20 founding members, 18 for profit tech companies and two nonprofit. And overall, since our first launch, which happened back in August, we've sustained on average 58% of attendance to these overall founding member meetings that are held monthly. You also notice while we're to the right, I mentioned how many participants are in each working group. The working groups are formed by founding members. So the 20 companies that are part of our organization are the ones who are in these working groups. We hope to get more experts into the working groups, and this is really where we'd love to learn more from MediGov and see how it is that we can pull up and see if there's any opportunity for us to maybe invite your own experts from a very large network. I'll turn it over to Patrick now.

Speaker 2: Cool. Thanks, Stephanie. I was actually, looking at I was about to try to type out some responses to stuff in the in the chat, but I'll get back to that in a moment. So why don't we go to, yeah, the next one, which is public policy. So we're excited. Last month, we, did our very first submission. This was in response to the U. S. White House, developing a new, what they call AI action plan. So we submitted a a set of comments. They're on our website if you want to take a look. And they really go at a couple of ideas. One is agency, right? So, everybody's talking about the AI agents and yet not talking so much about what that means at a deeper philosophical level. And so we try to unpack that a bit to say, look, there's two different ways of thinking about that, which is to say if you are an agent, and we can maybe move to the next one, since somebody we can talk a bit more. Then, sorry, next slide. Yeah. So this is the issue, the two dimensions of agency. That means one, making decision on behalf of somebody. And so that is what open AI calls agenticity. Right? And that's a a taking actions in the world, a measure of capability. That's all fine and good. But the second part that they don't really ever talk about is on behalf of someone else. Right? You have to be an agent in order you have to have a relationship. You have to have a sense of privity, to use a legal term, with the person you're serving. And that tends to get lost in all of these conversations. So we coined the term agentiality as the other side of this, which is the on behalf of someone else, the degree to which this agent is actually authorized to do something on my behalf or in my name going forward, which is the classic elements of the end user principal relationship. So those are the two dimensions of AI agency that we bring up in the, in the pleading. If you can go back one, one slide, Stephanie. So in the following itself, we suggest agenticity, the idea of creating more capability, would be supported by AI to AI interoperability. So today, of course, we have an interoperable web. People can go to websites. People can can share content and applications online. We don't have that today in the in the very early days of AI systems. Right? They're very much siloed based on the underlying entity that you're working with, whether it's OpenAI or or Perplexity or Google or many others. So if you had interoperability, then my agent could talk to your agent. And and so, and there's lots of benefits, so we can come from that. And so we propose an open standards approach maybe through IEEE. And then on the agent reality idea, we go back to what we just talked about. Net fiduciaries and other kinds of trusted intermediaries acting under fiduciary duties can ensure that the agents that are representing our interests, they're not, as Bruce Schneier puts it, double agents, which we think are acting our behalf, but are really not. It's more like a James Bond thriller where we find out at the end, oops, sorry. I'm actually not your agent. I'm working for Sam Altman. Too bad. So that's the idea of having trusted, trustworthy intermediaries. Okay. Yeah. And next one, Stephanie. And then this is sort of an attempt to show how those two elements work together. Some of you may remember Clippy, our good friend from the late nineties that Microsoft put on our, put on our screens for apparently no good reason. Clippy is a great example because, I mean, aside from being incredibly annoying, Clippy really didn't do very much. It didn't have a whole lot of ability to do anything for us, nor did it really have any kind of relationship to us. It was just sort of there. So if you think of Clippy as sort of like the the the zero zero part of the graph, now we're moving ahead into the world of assistants and avatars, semi and eventually autonomous, semi and fully autonomous agents, on the capability side. And our proposal is as you moved through that power relationship or that power, capabilities, you need the relationship at the same time. You basically need a more deeper human relationship the more powerful these agents become. So that is, okay. Thanks, Steve. Yeah. I was about to change that in the in the in the in the chat, and I sent it to you the wrong, so thanks for putting that out there. Anyway, so that's the idea of, like, that that sort of a relationship between those two dimensions. Next one is Stephanie. So this is a list of our directory. Lots of folks there. Consumer reports is probably the name you'll recognize immediately. We're really thrilled to have them, and they are interested in becoming one of the first net fiduciaries in the world on behalf of their 6,000,000, users, which is great. So we are in the process of trying to make that happen. Lots of other interesting tech companies there. Some of them do things with data. Several of them work on AI. Personal AI does a small language model approach, on that sort of thing. And then finally, this is just a little a quick attempt to sort of put them in the eco the the classic ecosystem of content apps, logical and physical layers. We even have an IoT company, Helpful Places, which is doing some amazing things, working with cities to make the sensors and devices and cameras in the smart city environment transparent, and interactive for the average passerby in an environment. So you don't feel like you're walking through a space without having a sense of who's doing what for what official reasons in ways that hopefully give you assurance that that they are operating in in your interests and give you a opportunity to have recourse if you're concerned, have questions. So that's we're great to we're really happy to have them on on board as well. So those are sort of that's a quick roster. Here in our leadership is is me, as the president and chief clinic clinic evangelist. Stephanie, who you've already met, and then we have strategic adviser, Todd Kelsey, from Benedictine College, and then legal counsel from Wilkinson Barker, Jonathan Cohen. With that, I'm happy to go back into the feed and also read up on what people have been putting there in the chat, but I appreciate your time. And, yeah, I love love your love your thoughts and questions at this point. Thank you.

Speaker 1: Awesome. Thank you guys so much. Yeah. If there are any questions in the chat that folks want to give voice to, feel free to do so. I got mine answered.

Speaker 2: Yeah. During Directly and indirectly. So hopefully that was helpful.

Speaker 1: Totally.

Speaker 2: Yeah. Funny. Could I could I ask you, Richard? Do you see net fiduciaries sort of inside large organizations, or do you see them mostly as small businesses that, are exterior to those organizations and certify them or rate them and so forth? Yeah. That's a great question. So I I think it could go in a number of different directions. Interestingly, the World Economic Forum wrote a paper about three years ago on data intermediaries, and they they try to classify it. And one particular role they had was what they called a data steward, which is an individual within, let's say, a large enterprise whose job is to ensure that things happening with the data flows are all done in a certain ethical manner, you know, consistent with whatever policies the enterprise has adopted. It's even it's more than just, like, a chief privacy officer. It has to do with with being a good steward around interactions with all the data that are collected and analyzed on behalf of the customer or client for an enterprise. So I think there is a there's a potential role for having an individual just says, I become a net fiduciary. I become that within a company, or I put my shingle out and and, you know, use it as a way to help companies, help nonprofits, for example, adopt some of these policies so so they can, you know, have that similar sort of conveying to the world that they're operating under those principles. I think it's at this point, at least in my mind, it's a fairly flexible standard in in terms of in what situations it can apply. But it comes down to having an agreement around what those specific duties are and then recourse on the back end, some sort of enforcement if things go wrong. I wanna make sure consumers, you know, ordinary people are protected. So it's not just you know, something that you you sort of you hope you hope for the best will happen. There's actually a potential role with with government. So I've talked to folks I know in the states of Colorado and California in the attorney general's offices. Because I'm I'm, you know, I'm a lawyer, and I'm happy to to have, let's say, in this case, a state AG be their back end enforcer. If something goes wrong, somebody is certified as a fiduciary, then they go off and do terrible things. You can take the trust mark away, but maybe there's more than that. Maybe it's also, you what? We're gonna we're gonna fine you with the power of the state for having held yourself out in a way that was basically committing fraud on the on the consumer. So that enforcement element, I think, has to be there and one of the many things we're exploring as part of the community of practice. Let's see. Well, share thoughts on why the ecosystem are ready for prime time. Thanks for that question, Larry. I'd love to say, you know, tomorrow, but this is a community approach. And be and one of the things I'm really happy about, we have 20 actual companies, mostly as pre seed, some, you know, early seed round, every day in the market confronting all these kinds of challenges and conflicts and trying to take on board these principles while still making money, and convincing, you know, convincing customers, convincing advisors, convincing, very importantly, investors that this is the way to go. So part of what we're doing now is just is that part, right, is to say that, yes, we believe, not just because we say it, but because we see it in real time, that there is a viable marketplace for this to happen. And so right now, it's sort of that proving period while behind the scenes, as Stephanie noted, we have the working groups churning out, you know, the different elements, you know, for business model policies, practices, etcetera. So we're doing that all in in conjunct in more or less in parallel. I would love for us to be able to say sometime in 2026 with that we are there, that we wake up and Consumer Reports is out in the world saying, we are the world's first net fiduciary. Here's what it means. Here's our trust mark. Here's our AI agent helping you with a bunch of stuff. You know, come join us. Come work with us. So that is my goal. A lot depends on outside, funding and other things that we can try to accelerate as quickly as possible. So, yeah, that's that's where we are at this moment. Liz has something. Medica went out for trusted immune service deliberation. Yeah. Please. So so one thing again, you know, the notion of a trusted intermediary can mean different things to different people. Right? So I in my my own conception, it has to do with fiduciary duties because I feel like there's a very long, rich common law around that that helps us understand what it means and doesn't mean. And and the challenge really is just taking that and applying it into the modern world to the web in particular, where there are permutations and elements that are challenging, but it's still, I think, doable. There are other ways of of conveying trust. Right? You you could have a data trust where it's collectivizing decisions, where people are involved at the get go, and there's inclusion, and everybody is represented. Right? And so it's very democratic. That's another form of trust building, which I think is absolutely terrific. And then if you use then fiduciary duties or elements on the outcome of that, right, sort of attach that to whatever comes from that process. That could be another way to do it or some other indicia of trust. It doesn't have to be fiduciary duties, by any means. But I think the point is, I think there's lots of ways to sort of get there. Even just having the conversation around have having trusted intermediaries is a big step beyond where we've been with the web to this point, from my perspective. Steve, document developed and states are mapped out, different possible types of fisheries. Not yet. It's it's in the making, Steve. Again, we've been at this for about six months. We're we're thrilled that we have the companies we have doing the things they're doing. And right now, it's a Stephanie and me. It would be great. We're hoping, again, with some additional resources to build out staffing, bring in, you know, convenings with academics and advisors and really, really, you know, people much smarter than I to help us create that sort of intellectual infrastructure, but we're we're not quite there yet. So, if you folks at MediGov again or other folks who are there, as part of this this group have ideas around that or or contacts, we're happy to happy to hear it. Company's a chat g p t wrapper. They would not be able to follow rules. Yeah. That's right. I mean, a company could say what they're doing is as a fiduciary, but if the underlying technology does not obey that, then I think it's a hard that's a case of where, again, the governance and the technology are clashing. So I don't think they'd be able to to say that. Any other thoughts, questions, comments, brickbats?

Speaker 1: No. I mean, I I love the, community of practice. Obviously, I think that's, like, a really solid way of, yeah, getting, like, theory out of practice, also informing practice from theory, like, that kind of, duality is really key. So I'm curious, yeah, like, what you are learning from the companies and, like, yeah, getting into the, like, the companies that are in the weeds, what are kind of some themes that are emerging around, yeah, the privacy policies or terms of service or just even just ways that they're doing things differently? What are the some practice?

Speaker 2: One thing we're learning, which is fascinating to me, and, thankfully, it sort of aligns with where I was I I'm in in one part of the book. There are two models that people have been talking about the last ten years around around helping people with data. Right? One is this sort of like a data protector. Right? So it's this build, demote, and then, you know, someone mentioned in the in the chat, like, Norton has their thing, LifeLock. Right? We'll help you protect you, pay us us $10.20 bucks a month. Right? That has some utility. Right? But it's fairly minimal as far as it goes. So that's one business model. The other one is monetization. Right? We're gonna help you monetize your personal data. We're gonna get Meta to send you a $7 check every month. Isn't that great? Right? I think what we're learning, and all the companies have already been you know, as I talk to each of them, the founders and what they're trying to do, neither of those models really moves the needle very much for the consumer. The consumer yeah. Sure. Protect my data, but half the time, they don't know where it's going. Anyway, how do I protect how do I trust Norton? What's Norton doing with the data that I'm they're supposedly trust you know? Right? So there's it sort of creates this sort of receding, like, where's the trust actually going with these folks who who show up? And I'm not trying to demean anything about Norton, but but, you know, I think, anyway, it doesn't seem like on its face, it's enough to create a really big robust way of representing people. And the same thing with monetizing data. That's the one that a lot of companies have really been focusing on. And for the most part, it's been a failure. I think because people wanted, what is my data? You know, what's it worth? What I really care? I think the thing that they all the companies are all realizing is it's about creating the actual relationship. If I have a relationship with the consumer, I can help them. Right? And I can solve everyday real world problems. So I'll just give you a quick one. Consumer Reports, their first two use cases for the AI agent they're building. The first one is to help me with customer service complaints. Right? So Verizon owes me $30. The AI agent will have authorization to go ask me into the account, interact, knock on the door, interact with the inevitable Verizon bot, say, come on. You owe me $30. Give it away. Give it to us. Right? Get the $30 back, hopefully, which saves me time and money and aggravation, and then maybe consumer reports gets a finder's fee, you know, 50Â¢ or a dollar, whatever the consumer consumer agrees to. Right? That's the first use case. The second use case is manage all of my subscriptions. I've got I don't know how many subscriptions to online content, to video feeds, to all this stuff. I don't know where half the time, what credit card they're on anymore. I don't know what the terms are. I don't know when they increase. I don't know when I can get out of it. If I had a bot or an agent that could manage all of that on a real time basis and say, hey. Guess what? Netflix is about to raise their rates $5, but I can get you an extra discount for another six months because I negotiated that with them. Right? You could save me time, aggravation, and money. You know, tell me that there's a subscription I have that I didn't even know I had. I haven't used it for a year. Great. Let's get rid of it. Move on. So that's a to me, those are two really great examples of pain points that you're helping people with, that you need a relationship, that people have trust, but you can show real time to the individual the benefit they're getting, and then consumer reports gets a little piece of that. So those are that that's what they're doing, and that's what a lot of the member companies are working on. What are legitimate pain points that you can help people with in their lives beyond monetize my data or protected it, you know, behind a moat? So, anyway, that's a very long rambling answer, but those are early days of things I'm picking up on that are pretty interesting from working with these companies. What kind of players might be missing from the mix? We have a nice blend of we have four AI companies. We have three data analytics companies. We have several data consumer app facing companies. We have the smart city IoT project. I think more social media, frankly, folks involved there would be great. Val's with Reliable, or has been working with Reliable. They're a member company, which is awesome. And they do some great stuff in terms of helping annotate data, that goes into social media, etcetera. But I'm sure there are some other type social media platforms out there that we could work with. One idea is the notion of middleware, which is basically substituting my recommendation engine for, you know, what Meta or Amazon or Netflix thinks I should be interacting with. Maybe that becomes its own sort of use case. I could swap out somebody's decision engine for my own. Why do I why do I care what you know, again, picking all my friends at Meta. What do I care what Mark Zuckerberg thinks I should be watching? I wanna watch what I wanna watch, my own news feed, my entertainment feed, my social media feed. I mean, Blue Sky does a little bit of that, but but more so, you know, giving even more of that back to the, the the end user, the customer to manage. So people sort of more involved in that space would be really interesting to have in the mix as well. And, again, the notion of it being for profit companies is not to exclude others. I love folks in the in the NGO world. It's just I'm trying to prove the hard case. I wanna prove you could be ethical and successful commercially. And that's, I mean, that's what we're attempting to to demonstrate. Yeah. Helpful places. Jackie Liu, who I worked with at Google when they had the the project in the sidewalk labs in in Toronto, which was shut down in 2020. But Jackie was working on this this early days DTPR, which is a a way of, as I mentioned in the conversation earlier, ways to interact with the environment so that I can see what's happening with the sensors and devices there in a real time basis and interact with it, lodge complaints, and whatever, is working with half a dozen actual cities in The United States, doing some great stuff and happy to have them as a as a member company too. Any other questions? I

Speaker 1: saw back a little bit up. You mentioned a paper, and I was also curious to get the link to it about kind of one of the maybe it was, like, trusted intermediaries. One of the concepts that kind of is, like, a similar predecessor to netfiduciary that was inspiring to you all. There was a paper.

Speaker 2: Oh, the the information fiduciaries? Was that the one? Excuse me. Balkan and Zittrain? Are you talking about one of the ones we've recently?

Speaker 1: No. I think I think it was that one then.

Speaker 2: Yeah. So so Jack Balkan and Jonathan Zittrain at Harvard wrote several papers together on what they called information fiduciaries back in 2015 and '16. And the, and the notion was very similar to what we're doing here, except they would impose these obligations on the web platforms. Fascinatingly, Leena Khan, before she became chair of the Federal Trade Commission in The US, wrote a paper that basically said, no, you can't do that because now you're violating the terms of corporate law. Under corporate law, and particularly in Delaware, you know, as we understand it here, generally United States, the shareholders are basically the clients or the customers. The customer really isn't. So, if you're doing something by imposing an obligation on them to have a duty of loyalty to the consumer, that's in direct violation of their ultimate loyalty, that's in direct violation of their ultimate loyalty, their fiduciary duty internally in the corporate sense to the shareholders. So I thought that was actually a very compelling argument on her behalf, and I didn't I think, you know, they they attempted to sort of push back on that, and I didn't frankly find response all that convincing. And then the other piece is just simply even if that wasn't the case, at the end of the day, if it becomes an obligation, then it becomes compliance. Becomes compliance, it means doing the minimal necessary to keep my CEO out of jail. And that, to me, is not the same thing as having a robust duty of loyalty. Tamar Frankel, who's an expert in the field, written a bunch of books about this stuff, has a great phrase. She says, forced loyalty is no loyalty at all. And And I think that's absolutely true. So, that's why if you want to have a duty of care on these companies, sure, that lower layer that I mentioned earlier from the pet model, that has happened in a bunch of industries. Lots of it is in Europe, but some in The US as well. That's okay. The the do no harm standard should be pretty sacrosanct as something that companies don't do. This money moved to the loyalty tier that then, at least in The States, you start creating that conflict with corporate law.

Speaker 1: Fascinating. Well, we are

Speaker 2: I can I can get you to this? I'm sorry. Long as Saint Val. I can try to I don't have the links right here, but we can try to find copy of those papers from Citranium.

Speaker 1: Yeah. Yeah. Feel free to post any follow-up links, like the link to the slide deck for sure, any of the papers that you mentioned, or maybe if you have the public, comment that you made on the, US AI action plan. Like, any links like that, you can sometimes folks will post those in, like, the thread on our Slack so that we can continue to do research. And if anyone has any other questions for y'all, then you can post them there in that channel so that everyone can see. But thank you both so much for coming and sharing with us. Yeah. For

Speaker 2: having us. Appreciate it. Great to

Speaker 1: be safe. Hopefully, the beginning of lots of more conversations, collaborations to come. So, everyone, please unmute, and let's give our presenters a round of applause.

Speaker 2: At

Speaker 3: mute again. Once.

Speaker 2: I hear muted once, but that's all fine. Yeah. Exactly. I can see It's all, like, like, the noise cancellation. Yeah. Exactly. Yeah. Thank you all again. You all. And have a good rest of your week.

Speaker 1: Yes. You too. Bye, everyone. See you next week.

Speaker 2: Bye bye.